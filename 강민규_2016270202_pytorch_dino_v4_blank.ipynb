{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "nlp-sequence-models",
      "graded_item_id": "1dYg0",
      "launcher_item_id": "MLhxP"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "pytorch_dino_v4_blank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7URVQh6Pkeff",
        "outputId": "9ca62c56-7a9c-4389-feb2-296d37588b98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NKelsLcfkg9I",
        "outputId": "c7d44b41-bb37-4960-92bd-be4eaab0d1c6"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/ML_class/13_Dino')\n",
        "%pwd"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/ML_class/13_Dino'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNBYhxrxWwrY"
      },
      "source": [
        "# Character level language model - Dinosaurus land\n",
        "\n",
        "** This problem comes from Andrew Ng's coursera course. Instead of using their Keras-based solution, we will try to solve this problem based on PyTorch.**\n",
        "\n",
        "Imagine that leading biology researchers are creating new breeds of dinosaurs and bringing them to life on earth, and your job is to give names to these dinosaurs. If a dinosaur does not like its name, it might go beserk, so choose wisely!  \n",
        "\n",
        "Luckily you have learned some deep learning and you will use it to save the day. To create new dinosaur names, you will build a character level language model to generate new names. Your algorithm will learn the different name patterns, and randomly generate new names. \n",
        "\n",
        "\n",
        "By completing this assignment you will learn:\n",
        "\n",
        "- How to store text data for processing using an RNN \n",
        "- How to synthesize data, by sampling predictions at each time step and passing it to the next RNN-cell unit\n",
        "- How to build a character-level text generation recurrent neural network\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBB7zebSWwrZ"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.functional import F\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TW1_HvVCWwrc"
      },
      "source": [
        "## Dataset and Preprocessing\n",
        "\n",
        "Run the following cell to read the dataset of dinosaur names, create a list of unique characters (such as a-z), and compute the dataset and vocabulary size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5fEBDl0Wwrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87723152-20b4-4f15-f748-aade65c0ccc9"
      },
      "source": [
        "def split_to_names(fname):\n",
        "    EOS = \"<EOS>\"\n",
        "    data = []\n",
        "        \n",
        "    with open(fname) as file:\n",
        "        text = file.read().lower()\n",
        "            \n",
        "    names = text.splitlines()\n",
        "    for i, name in enumerate(names):\n",
        "        # Split names to chars and append the End of Sequence (EOS) Token\n",
        "        ch_list = list(name) + [EOS]\n",
        "        data.append(ch_list)\n",
        "    return data\n",
        "\n",
        "dino_list_in_char = split_to_names(\"dinos.txt\")\n",
        "\n",
        "print(dino_list_in_char[0])\n",
        "print(dino_list_in_char[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '<EOS>']\n",
            "['a', 'a', 'r', 'd', 'o', 'n', 'y', 'x', '<EOS>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4MwqUAFWwrf"
      },
      "source": [
        "The characters are a-z (26 characters) plus the \"\\n\" (or newline character), which in this assignment plays a role similar to the `<EOS>` (or \"End of sentence\") token we had discussed in lecture, only here it indicates the end of the dinosaur name rather than the end of a sentence. \n",
        "In the cell below, we create a python dictionary (i.e., a hash table) to map each character to an index from 0-26. We also create a second python dictionary that maps each index back to the corresponding character character. This will help you figure out what index corresponds to what character in the probability distribution output of the softmax layer. Below, `char_to_ix` and `ix_to_char` are the python dictionaries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD4Yl9uIWwrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4f43e5-571c-4653-f931-7d7b64d82e7b"
      },
      "source": [
        "char_vocab = [\"<EOS>\"] + sorted([ch for ch in string.ascii_lowercase])\n",
        "\n",
        "char_to_ix = {ch:i for i,ch in enumerate(char_vocab)}\n",
        "ix_to_char = {i:ch for ch,i in char_to_ix.items()}\n",
        "\n",
        "print(char_to_ix)\n",
        "print(ix_to_char)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<EOS>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{0: '<EOS>', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2W0-ZuAWwrj"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxtrXX5edDPO"
      },
      "source": [
        "def keys_to_values(keys, _map, default):\n",
        "    return [_map.get(key, default) for key in keys]\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_as_str, _map):\n",
        "        self.data_as_int = []\n",
        "        \n",
        "        # Convert characters to integers\n",
        "        for seq_as_str in data_as_str:\n",
        "            seq_as_int = keys_to_values(seq_as_str, _map, random.choice(list(_map)))\n",
        "            self.data_as_int.append(seq_as_int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_as_int)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        # Get data sample at index ix\n",
        "        item = self.data_as_int[ix]\n",
        "        \n",
        "        # Slice x and y from sample\n",
        "        x = item[:-1]\n",
        "        y = item[ 1:]\n",
        "        return torch.tensor(x), torch.tensor(y)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCAJnAFWjLvM",
        "outputId": "c1a9960f-2cc0-4fc8-bd29-aa7d933d430a"
      },
      "source": [
        "dataset = Dataset(dino_list_in_char, char_to_ix)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "xx, yy = dataset.__getitem__(0)\n",
        "\n",
        "print(\"x from dataset:\", xx)\n",
        "print(\"y from dataset:\", yy)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x from dataset: tensor([ 1,  1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19])\n",
            "y from dataset: tensor([ 1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19,  0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psvBNlY4rI97",
        "outputId": "b762fc8d-bae1-4fa1-f67f-c0d191b0f79d"
      },
      "source": [
        "t_embedding = nn.Embedding(num_embeddings=27, embedding_dim = 8)\n",
        "t_embed = t_embedding(xx)\n",
        "print(t_embed)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 7.9782e-01, -1.1143e+00,  7.2452e-01, -6.7979e-01,  6.6525e-01,\n",
            "          2.6419e-01, -1.0812e+00,  9.2673e-01],\n",
            "        [ 7.9782e-01, -1.1143e+00,  7.2452e-01, -6.7979e-01,  6.6525e-01,\n",
            "          2.6419e-01, -1.0812e+00,  9.2673e-01],\n",
            "        [-9.3449e-01, -1.8960e+00,  1.2122e+00,  8.7883e-01,  2.4871e-01,\n",
            "          1.9022e+00, -3.8622e-02, -3.0282e-01],\n",
            "        [ 1.3868e+00,  5.5180e-01,  1.1814e+00, -1.8047e-01, -2.8038e-01,\n",
            "          1.2594e-01,  2.5039e-02, -8.4645e-01],\n",
            "        [ 3.4575e-01, -1.3811e+00, -1.9646e+00,  1.2649e+00,  1.6956e-01,\n",
            "          1.9174e+00, -1.0950e+00, -2.5998e-01],\n",
            "        [-1.9730e+00, -1.1149e+00, -1.3436e+00,  4.9206e-01,  7.3054e-01,\n",
            "         -4.2840e-01, -3.9060e-01, -4.2865e-01],\n",
            "        [-4.9653e-01,  8.2501e-01, -9.3854e-01, -1.1112e+00,  5.5174e-01,\n",
            "          3.4763e-01, -1.1441e+00,  1.3646e-01],\n",
            "        [ 6.1975e-01, -4.1251e-01, -1.5244e+00, -3.3758e-01,  7.0547e-01,\n",
            "         -1.1381e+00, -3.5191e-01, -2.3472e-01],\n",
            "        [ 7.9782e-01, -1.1143e+00,  7.2452e-01, -6.7979e-01,  6.6525e-01,\n",
            "          2.6419e-01, -1.0812e+00,  9.2673e-01],\n",
            "        [ 4.0249e-01, -1.4367e+00,  1.6722e-01, -3.0175e-01, -1.7683e+00,\n",
            "          3.1723e-01,  2.9182e-01, -6.7596e-01],\n",
            "        [ 1.4166e+00, -9.9418e-01,  5.1611e-04,  2.5872e-01,  1.6383e-01,\n",
            "         -1.1903e+00,  5.5938e-01,  3.7297e-01],\n",
            "        [ 4.0249e-01, -1.4367e+00,  1.6722e-01, -3.0175e-01, -1.7683e+00,\n",
            "          3.1723e-01,  2.9182e-01, -6.7596e-01],\n",
            "        [ 6.1975e-01, -4.1251e-01, -1.5244e+00, -3.3758e-01,  7.0547e-01,\n",
            "         -1.1381e+00, -3.5191e-01, -2.3472e-01]], grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "xizc13QQWwrk"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVH2D8AlWwrk"
      },
      "source": [
        "Build a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGZ0I_AuWwrl"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, _map, hidden_size, emb_dim=8, n_layers=1, dropout_p=0.2):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.vocab_size  = len(_map)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.emb_dim     = emb_dim\n",
        "        self.n_layers    = n_layers\n",
        "        self.dropout_p   = dropout_p\n",
        "        \n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.vocab_size,\n",
        "            embedding_dim =self.emb_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size =self.emb_dim,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers =self.n_layers,\n",
        "            batch_first=True)  # if True, input and output tensors are in (batch, seq, feature)\n",
        "        \n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features =self.hidden_size,\n",
        "            out_features=self.vocab_size)\n",
        "        \n",
        "    def forward(self, x, init_state):\n",
        "\n",
        "        # x : (batch, seq)\n",
        "        # prev_state = (h, c)\n",
        "        # h, c : (layer, batch, hidden_size)\n",
        "        n_b, n_s = x.shape\n",
        "        \n",
        "        # embed = (batch, seq, embed)\n",
        "        embed = self.embedding(x)\n",
        "\n",
        "        # lstm's input : embed, (h_0, c_0)\n",
        "        # lstm's output: y, (h_n, c_n)\n",
        "        #                y : (batch, seq, hidden_size)\n",
        "        # *** y_n == h_n\n",
        "        # refer to https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "\n",
        "        # lstm\n",
        "        yhat, final_state = self.lstm(embed,init_state)\n",
        "        \n",
        "        # dropout\n",
        "        yhat = self.dropout(yhat)\n",
        "        \n",
        "        # fully connected layer\n",
        "        out = self.fc(yhat)\n",
        "        \n",
        "        return out, final_state\n",
        "    \n",
        "    def init_state(self, b_size=1):\n",
        "        return (torch.zeros(self.n_layers, b_size, self.hidden_size),\n",
        "                torch.zeros(self.n_layers, b_size, self.hidden_size))\n",
        "\n",
        "model = Model(char_to_ix, 64, 8, n_layers=1, dropout_p=0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsryFHMEWwr4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQgsK-OHuNmy",
        "outputId": "f04c3059-5559-462c-ac2c-c2399a54c113"
      },
      "source": [
        "def train(model, data, num_iter, criterion, clip=0.25, lr=0.001, print_every=50):\n",
        "    model.train()\n",
        "    \n",
        "    costs = []\n",
        "    running_loss = 0\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    curr_iter = 0\n",
        "    while curr_iter<num_iter:\n",
        "        for x, y in data:\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Initialise model's state and perform forward-prop\n",
        "            init_state = model.init_state(b_size=x.shape[0])\n",
        "\n",
        "            #def forward(self, x, init_state):\n",
        "            # forward propagation\n",
        "            out, state = Model.forward(model,x,init_state)\n",
        "\n",
        "            # Calculate loss\n",
        "            # criterion's input : (batch, class) --> out (1, seq, class)\n",
        "            # criterion's target : (batch)  --> y (1, seq)\n",
        "            loss = criterion(out.transpose(1, 2), y)\n",
        "            costs.append(loss.item())\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate gradients and update parameters\n",
        "            loss.backward()\n",
        "            if clip:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            \n",
        "            curr_iter += 1\n",
        "            if print_every and (curr_iter%print_every)==0:\n",
        "                print(\"Iteration: {:{}}/{}, Loss: {:8.4f}\".format(\n",
        "                    curr_iter, int(math.log(num_iter, 10))+2, num_iter,\n",
        "                    running_loss/float(print_every)))\n",
        "                running_loss = 0\n",
        "                \n",
        "            if curr_iter>=num_iter:\n",
        "                break\n",
        "    return model, costs\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model, costs = train( model, dataloader, 50000 , criterion, clip=0.25, lr=1e-3, print_every=1000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:   1000/50000, Loss:   2.2984\n",
            "Iteration:   2000/50000, Loss:   1.9506\n",
            "Iteration:   3000/50000, Loss:   1.8768\n",
            "Iteration:   4000/50000, Loss:   1.7852\n",
            "Iteration:   5000/50000, Loss:   1.7502\n",
            "Iteration:   6000/50000, Loss:   1.7064\n",
            "Iteration:   7000/50000, Loss:   1.6576\n",
            "Iteration:   8000/50000, Loss:   1.6539\n",
            "Iteration:   9000/50000, Loss:   1.6036\n",
            "Iteration:  10000/50000, Loss:   1.5983\n",
            "Iteration:  11000/50000, Loss:   1.5843\n",
            "Iteration:  12000/50000, Loss:   1.5498\n",
            "Iteration:  13000/50000, Loss:   1.5719\n",
            "Iteration:  14000/50000, Loss:   1.5035\n",
            "Iteration:  15000/50000, Loss:   1.5141\n",
            "Iteration:  16000/50000, Loss:   1.4842\n",
            "Iteration:  17000/50000, Loss:   1.4962\n",
            "Iteration:  18000/50000, Loss:   1.4772\n",
            "Iteration:  19000/50000, Loss:   1.4538\n",
            "Iteration:  20000/50000, Loss:   1.4409\n",
            "Iteration:  21000/50000, Loss:   1.4461\n",
            "Iteration:  22000/50000, Loss:   1.3866\n",
            "Iteration:  23000/50000, Loss:   1.4157\n",
            "Iteration:  24000/50000, Loss:   1.4107\n",
            "Iteration:  25000/50000, Loss:   1.3733\n",
            "Iteration:  26000/50000, Loss:   1.3651\n",
            "Iteration:  27000/50000, Loss:   1.3423\n",
            "Iteration:  28000/50000, Loss:   1.3692\n",
            "Iteration:  29000/50000, Loss:   1.3408\n",
            "Iteration:  30000/50000, Loss:   1.3454\n",
            "Iteration:  31000/50000, Loss:   1.3558\n",
            "Iteration:  32000/50000, Loss:   1.2923\n",
            "Iteration:  33000/50000, Loss:   1.3221\n",
            "Iteration:  34000/50000, Loss:   1.2977\n",
            "Iteration:  35000/50000, Loss:   1.2948\n",
            "Iteration:  36000/50000, Loss:   1.2835\n",
            "Iteration:  37000/50000, Loss:   1.2864\n",
            "Iteration:  38000/50000, Loss:   1.2567\n",
            "Iteration:  39000/50000, Loss:   1.2693\n",
            "Iteration:  40000/50000, Loss:   1.2758\n",
            "Iteration:  41000/50000, Loss:   1.2526\n",
            "Iteration:  42000/50000, Loss:   1.2156\n",
            "Iteration:  43000/50000, Loss:   1.2584\n",
            "Iteration:  44000/50000, Loss:   1.2086\n",
            "Iteration:  45000/50000, Loss:   1.2547\n",
            "Iteration:  46000/50000, Loss:   1.2026\n",
            "Iteration:  47000/50000, Loss:   1.2031\n",
            "Iteration:  48000/50000, Loss:   1.1997\n",
            "Iteration:  49000/50000, Loss:   1.2141\n",
            "Iteration:  50000/50000, Loss:   1.1696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "903NgzTQ0cAC"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fAt8WgKl0bLb",
        "outputId": "4776564f-b65e-408c-d382-8f7a1448ab49"
      },
      "source": [
        "cum = 300\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Cross-Entropy Loss\")\n",
        "plt.plot([sum(costs[i:i+cum])/cum for i in range(0, len(costs), cum)])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb2bcbef750>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhllHYQc0hXb"
      },
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGqVI6cZ0lg1"
      },
      "source": [
        "def sample_next(model, x, prev_state, topk=5, uniform=True):\n",
        "    # Perform forward-prop and get the output of the last time-step\n",
        "    out, state = model(x, prev_state)\n",
        "    last_out = out[0, -1, :]\n",
        "\n",
        "    # Get the top-k indexes and their values\n",
        "    topk = topk if topk else last_out.shape[0]\n",
        "    top_logit, top_ix = torch.topk(last_out, k=topk, dim=-1)\n",
        "    \n",
        "    # Get the softmax of the topk's and sample\n",
        "    p = None if uniform else F.softmax(top_logit.detach(), dim=-1).numpy()\n",
        "    sampled_ix = np.random.choice(top_ix, p=p)\n",
        "    return sampled_ix, state\n",
        "\n",
        "\n",
        "def sample(model, seed, topk=5, uniform=True, max_seqlen=18, stop_on=None):\n",
        "    seed = seed if isinstance(seed, (list, tuple)) else [seed]\n",
        "#    print(seed)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sampled_ix_list = seed[:]\n",
        "        x = torch.tensor([seed])\n",
        "        \n",
        "        prev_state = model.init_state(b_size=1)\n",
        "        for t in range(max_seqlen - len(seed)):\n",
        "            sampled_ix, prev_state = sample_next(model, x, prev_state, topk, uniform)\n",
        "\n",
        "            sampled_ix_list.append(sampled_ix)\n",
        "            x = torch.tensor([[sampled_ix]])\n",
        "            \n",
        "            if sampled_ix==stop_on:\n",
        "                break\n",
        "    \n",
        "#    model.train()\n",
        "#    print(sampled_ix_list)\n",
        "    return sampled_ix_list"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLt7-SXi1f6c",
        "outputId": "d8f29f2b-19a2-44ad-8a12-b267a8c5b34e"
      },
      "source": [
        "print(\">>> Samples where seed is a randomly chosen character.\")\n",
        "for i in range(10):\n",
        "    seed = random.choice(list(char_to_ix.values())[1:])\n",
        "    print(seed, \"=>\", \"\".join(keys_to_values(\n",
        "        sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"]),\n",
        "        ix_to_char, \"<?>\")))\n",
        "\n",
        "\n",
        "print(\">>> Samples where seed is a list of character.\")\n",
        "for i in range(3):\n",
        "    seed = keys_to_values(list(\"python\"), char_to_ix, char_to_ix[\"<EOS>\"])\n",
        "    print(seed, \"=>\", \"\".join(keys_to_values(\n",
        "        sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"]),\n",
        "        ix_to_char, \"<?>\")))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Samples where seed is a randomly chosen character.\n",
            "22 => valirusaurus<EOS>\n",
            "24 => xiasasaurus<EOS>\n",
            "25 => yurovenosaurus<EOS>\n",
            "10 => japtoraptor<EOS>\n",
            "25 => yanosaurus<EOS>\n",
            "24 => xinjingilurus<EOS>\n",
            "12 => lanangosaurus<EOS>\n",
            "1 => ampillasaurus<EOS>\n",
            "21 => untelesaurus<EOS>\n",
            "14 => naminisaurus<EOS>\n",
            ">>> Samples where seed is a list of character.\n",
            "[16, 25, 20, 8, 15, 14] => pythonotitan<EOS>\n",
            "[16, 25, 20, 8, 15, 14] => pythonoceratops<EOS>\n",
            "[16, 25, 20, 8, 15, 14] => pythonosponyx<EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvBM2S9bWwr4"
      },
      "source": [
        "**References**:\n",
        "- This exercise took inspiration from Andrej Karpathy's implementation: https://gist.github.com/karpathy/d4dee566867f8291f086. To learn more about text generation, also check out Karpathy's [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n",
        "- For the Shakespearian poem generator, our implementation was based on the implementation of an LSTM text generator by the Keras team: https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ActpjIETWwr4"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "You can see that your algorithm has started to generate plausible dinosaur names towards the end of the training. At first, it was generating random characters, but towards the end you could see dinosaur names with cool endings. Feel free to run the algorithm even longer and play with hyperparameters to see if you can get even better results. Our implemetation generated some really cool names like `maconucon`, `marloralus` and `macingsersaurus`. Your model hopefully also learned that dinosaur names tend to end in `saurus`, `don`, `aura`, `tor`, etc.\n"
      ]
    }
  ]
}